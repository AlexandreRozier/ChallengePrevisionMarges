{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "import joblib\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/home/goubetcle/Documents/Pôle/Challenge 2022/data_challenge/data\"\n",
    "output_folder = \"/home/goubetcle/Documents/Pôle/Challenge 2022/data_challenge/outputs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prev = pd.read_feather(os.path.join(data_folder, \"df_prev_sans_obs2020.feather\"))\n",
    "df_prev = df_prev.loc[df_prev.echeance.isin([0.5,1,2,4])]\n",
    "df_prev[\"hh_mm_cible\"] = df_prev.date_cible.dt.hour + df_prev.date_cible.dt.minute / 60\n",
    "df_prev[\"prev_obs_gap\"] = df_prev.prev.values - df_prev.obs.values\n",
    "df_prev.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enr_capacity = make_zone_columns(df=df_prev[['date_cible', 'echeance', 'type', 'pi']].loc[df_prev.type.isin([\"eolien\", \"photovoltaique\"])], columns='type')\n",
    "df_enr_capacity.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meteo_fr = pd.read_csv(os.path.join(data_folder,\"meteo_fr.csv\"), header=0, sep=\";\").rename(columns={\"utc_datetime\":\"date_cible\"})\n",
    "df_meteo_fr[\"date_cible\"] = pd.to_datetime(df_meteo_fr.date_cible, utc=True)\n",
    "df_meteo_halfhour = df_meteo_fr.loc[df_meteo_fr.echeance == 1].copy()\n",
    "df_meteo_halfhour[\"echeance\"] = df_meteo_halfhour.echeance * 0.5\n",
    "\n",
    "df_meteo_fr = pd.concat([df_meteo_fr.loc[df_meteo_fr.echeance.isin([1,2,4])], df_meteo_halfhour], ignore_index=True)\n",
    "\n",
    "df_meteo_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meteo_zone_eol = pd.read_feather(os.path.join(data_folder, \"meteo_zone_echeance12_2016_2020_HRES_piEOL_smooth.feather\"))\n",
    "df_meteo_zone_pv = pd.read_feather(os.path.join(data_folder, \"meteo_zone_echeance12_2016_2020_HRES_piPV_smooth.feather\"))\n",
    "\n",
    "df_meteo_zone_eol = df_meteo_zone_eol.loc[df_meteo_zone_eol.echeance.isin([0.5,1,2,4])]\n",
    "df_meteo_zone_pv = df_meteo_zone_pv.loc[df_meteo_zone_pv.echeance.isin([0.5,1,2,4])]\n",
    "\n",
    "\n",
    "dirwindeol = compute_dirwind(df_meteo_zone_eol.u100.values, df_meteo_zone_eol.v100.values) * pi / 180\n",
    "df_meteo_zone_eol[\"cosphi100\"] = np.cos(dirwindeol)\n",
    "df_meteo_zone_eol[\"sinphi100\"] = np.sin(dirwindeol)\n",
    "df_meteo_zone_eol[\"ff100_cubic\"] = df_meteo_zone_eol.ff100.values ** 3\n",
    "df_meteo_zone_eol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prodpv_fc_q90 = pd.read_feather(os.path.join(data_folder, \"productionPV_FC_cielclair_q90.feather\"))\n",
    "df_fcpv = pd.DataFrame(dict(date_cible=np.unique(df_prev.loc[(df_prev.echeance.isin([0.5,1,2,4]))*(df_prev.type.isin(['consommation', 'eolien', 'photovoltaique']))][[\"date_cible\"]].values)))\n",
    "df_fcpv[\"yday_cible\"] = df_fcpv.date_cible.dt.day_of_year\n",
    "df_fcpv[\"hour_cible\"] = df_fcpv.date_cible.dt.hour\n",
    "df_fcpv[\"minute_cible\"] = df_fcpv.date_cible.dt.minute\n",
    "\n",
    "df_fcpv = df_fcpv.merge(df_prodpv_fc_q90, how=\"left\", \n",
    "                        on=[\"yday_cible\", \"hour_cible\", \"minute_cible\"])\n",
    "\n",
    "df_fcpv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(pred_type=None):\n",
    "    df_features = df_prev[['date_cible','type', 'prev', 'echeance', 'hh_mm_cible', 'obs']]\n",
    "    df_features['mois_cible'] = df_prev.date_cible.dt.month\n",
    "    df_features = expand_calendarfeatures(df_features)\n",
    "    \n",
    "    if pred_type == 'eolien':\n",
    "        #df_newfeatures = make_zone_columns(df_meteo_zone_eol[['date_cible', 'echeance', 'zone', 'cosphi100', 'sinphi100', 'ff100_cubic']])\n",
    "        #df_features = df_features.merge(df_newfeatures, on=['date_cible', 'echeance'], how=\"left\", sort=False)\n",
    "        df_features = df_features.merge(\n",
    "            df_enr_capacity[['pi_eolien']], on=['date_cible', 'echeance'], how=\"left\", sort=False)\n",
    "    elif pred_type =='photovoltaique':\n",
    "        #df_newfeatures = make_zone_columns(df_meteo_zone_eol[['date_cible', 'echeance', 'zone', 'tcc', 't2m', 'ssrd']])\n",
    "        #df_features = df_features.merge(df_newfeatures, on=['date_cible', 'echeance'], how=\"left\", sort=False)\n",
    "        df_features = df_features.merge(\n",
    "            df_enr_capacity[['pi_photovoltaique']], on=['date_cible', 'echeance'], how=\"left\", sort=False)\n",
    "        df_features = df_features.merge(df_fcpv[[\"date_cible\", \"clear_sky_FC\"]], how=\"left\", sort=False, on=\"date_cible\")\n",
    "    elif pred_type == 'consommation':\n",
    "        df_features = df_features.merge(df_meteo_fr, on=['date_cible', 'echeance'], how=\"left\", sort=False).fillna(method='bfill').fillna(method=\"ffill\")\n",
    "    elif pred_type == 'consommation_residuelle':\n",
    "        #df_newfeatures = make_zone_columns(df_meteo_zone_eol[['date_cible', 'echeance', 'zone', 'cosphi100', 'sinphi100', 'ff100_cubic']])\n",
    "        #df_features = df_features.merge(df_newfeatures, on=['date_cible', 'echeance'], how=\"left\", sort=False)\n",
    "        #df_newfeatures = make_zone_columns(df_meteo_zone_eol[['date_cible', 'echeance', 'zone', 'tcc', 't2m', 'ssrd']])\n",
    "        #df_features = df_features.merge(df_newfeatures, on=['date_cible', 'echeance'], how=\"left\", sort=False)\n",
    "        df_features = df_features.merge(df_meteo_fr, on=['date_cible', 'echeance'], how=\"left\", sort=False).fillna(method='bfill').fillna(method=\"ffill\")\n",
    "        df_features = df_features.merge(\n",
    "            df_enr_capacity, on=['date_cible', 'echeance'], how=\"left\", sort=False)\n",
    "        df_features = df_features.merge(df_fcpv[[\"date_cible\", \"clear_sky_FC\"]], how=\"left\", sort=False, on=\"date_cible\")\n",
    "    return df_features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_target = np.arange(0.005, 1, 0.005)\n",
    "pred_types = np.unique(df_prev.type.values)\n",
    "echeances = np.unique(df_prev.echeance.values)\n",
    "hh_mm_target = np.unique(df_prev.hh_mm_cible.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantile_prev_4x199 = df_prev[['date_cible', 'date_lancement','type', 'echeance', 'hh_mm_cible', 'prev']].loc[df_prev.date_cible.dt.year == 2020]\n",
    "n_examples = df_quantile_prev_4x199.shape[0]\n",
    "df_quantile_prev_4x199 = pd.concat([df_quantile_prev_4x199] * len(quantile_target), ignore_index=True)\n",
    "df_quantile_prev_4x199[\"quantile_niveau\"] = np.repeat(quantile_target, n_examples)\n",
    "df_quantile_prev_4x199[\"prev_q\"] = np.zeros(n_examples * len(quantile_target))\n",
    "df_quantile_prev_4x199 = df_quantile_prev_4x199[['date_cible', 'date_lancement', 'echeance', 'type', 'prev_q', 'quantile_niveau']]\n",
    "df_quantile_prev_4x199.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage de l'écart à la prevision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "situations = set([item for item in zip(df_quantile_prev_4x199.echeance.values,\n",
    "                                       df_quantile_prev_4x199.type.values,\n",
    "                                       df_quantile_prev_4x199.quantile_niveau.values                                      \n",
    "                                       )])\n",
    "\n",
    "len(situations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "def prepare_gbreg(quantile):\n",
    "    reg = GradientBoostingRegressor(loss='quantile', n_estimators=300, alpha=quantile, random_state=42, n_iter_no_change=33)\n",
    "    \n",
    "    gridparams = dict(\n",
    "        learning_rate=[0.01,0.035, 0.07, 0.1],\n",
    "        max_depth=[3, 7],\n",
    "        min_samples_split=[2,8],\n",
    "        max_features=[1.0, 'sqrt', 'log2'],   \n",
    "    )\n",
    "    \n",
    "    scorer = make_scorer(QuantileScore(q=quantile), greater_is_better=False)\n",
    "        \n",
    "    return GridSearchCV(reg, gridparams, scoring = scorer, refit=True, n_jobs=-2, cv=5, verbose=1)\n",
    "\n",
    "fixed_params = dict(loss='quantile', n_estimators=300, random_state=42, n_iter_no_change=33)\n",
    "\n",
    "@dataclass\n",
    "class BestParams:\n",
    "    q: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_pred = []\n",
    "best_params = {}\n",
    "\n",
    "DO_TRAIN = False\n",
    "\n",
    "index_cols = ['date_cible', 'echeance', 'type', 'hh_mm_cible', 'obs']\n",
    "\n",
    "for situation in tqdm(situations):\n",
    "    print(f\"Learning of situation {situation}\")\n",
    "    #prepare features\n",
    "    echeance, pred_type, quantile = situation\n",
    "    \n",
    "    df_features = prepare_features(pred_type=pred_type)\n",
    "    df_features = df_features.loc[(df_features.type.values == pred_type) * (df_features.echeance.values == echeance)]\n",
    "    \n",
    "    df_features_train = df_features.loc[df_features.date_cible.dt.year < 2020]\n",
    "    df_features_pred = df_features.loc[df_features.date_cible.dt.year == 2020]\n",
    "    \n",
    "    #training\n",
    "    df_modelpred = df_features_pred[['date_cible', 'echeance', 'type']]\n",
    "    df_modelpred[\"quantile_niveau\"] = np.ones(df_modelpred.shape[0]) * quantile\n",
    "    \n",
    "    x_train = df_features_train.drop(columns=index_cols).values\n",
    "    x_pred = df_features_pred.drop(columns=index_cols).values\n",
    "    \n",
    "    y_train = df_features_train.obs.values\n",
    "    \n",
    "    if DO_TRAIN:\n",
    "        if best_params.get(pred_type):\n",
    "            model = GradientBoostingRegressor(\n",
    "                alpha=quantile,\n",
    "                **fixed_params,\n",
    "                **best_params.get(pred_type)\n",
    "            )\n",
    "            model.fit(x_train, y_train)\n",
    "            print(model.score(x_train, y_train))\n",
    "            best_reg=model\n",
    "        else:\n",
    "            model = prepare_gbreg(quantile)\n",
    "            model.fit(x_train, y_train)\n",
    "            print(model.score(x_train, y_train))\n",
    "            best_reg = model.best_estimator_\n",
    "            best_params[pred_type] = model.best_params_\n",
    "        \n",
    "        #saving\n",
    "        filename = \"_\".join(str(it) for it in situation)+\"_gbregressor.sav\"\n",
    "        joblib.dump(best_reg, os.path.join(output_folder+\"/models/gb\",filename))\n",
    "        \n",
    "    else:\n",
    "        filename = \"_\".join(str(it) for it in situation)+\"_gbregressor.sav\"\n",
    "        best_reg = joblib.load(os.path.join(output_folder+\"/models/gb\",filename))\n",
    "    \n",
    "    y_pred = best_reg.predict(x_pred)\n",
    "    df_modelpred[\"prev_q\"] = y_pred\n",
    "    list_df_pred.append(df_modelpred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_final = pd.concat(list_df_pred, axis=0)\n",
    "df_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantile_prev_4x199= df_quantile_prev_4x199[['date_cible', 'date_lancement', 'echeance', 'type', 'quantile_niveau']].merge(\n",
    "    df_pred_final, how='left', sort=False, on=['date_cible', 'echeance',  'type', 'quantile_niveau']\n",
    ")[['date_cible', 'date_lancement', 'type', 'prev_q', 'quantile_niveau']]\n",
    "\n",
    "df_quantile_prev_4x199.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantile_prev_4x199.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mise en forme des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantile_prev_Q1Q99 = df_quantile_prev_4x199.loc[df_quantile_prev_4x199.type==\"consommation_residuelle\"].loc[\n",
    "    df_quantile_prev_4x199.quantile_niveau.isin([0.01, 0.99])].reset_index(drop=True)\n",
    "df_quantile_prev_Q1Q99.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantile_prev_4x199.to_feather(os.path.join(output_folder, \"CG_BrutGradientBoosting_4x199.feather\"), compression=\"zstd\")\n",
    "df_quantile_prev_Q1Q99.to_feather(os.path.join(output_folder, \"CG_BrutGradientBoosting_Q1Q99.feather\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xp_venv",
   "language": "python",
   "name": "xp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
