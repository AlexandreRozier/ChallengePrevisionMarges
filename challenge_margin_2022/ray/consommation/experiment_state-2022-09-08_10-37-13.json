{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00001\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 16,\n    \"lr\": 0.00027445835454753493,\n    \"dropout_rate\": 0.31204435245741635,\n    \"batch_size\": 128,\n    \"epochs\": 4\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 16,\n    \"lr\": 0.00027445835454753493,\n    \"dropout_rate\": 0.31204435245741635,\n    \"batch_size\": 128,\n    \"epochs\": 4\n  },\n  \"experiment_tag\": \"1_batch_size=128,dropout_rate=0.3120,epochs=4,layer_1=16,lr=0.0003\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"trial_id\": \"6fbf4_00001\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1662626236.7501292,\n  \"relative_logdir\": \"train_with_config_6fbf4_00001_1_batch_size=128,dropout_rate=0.3120,epochs=4,layer_1=16,lr=0.0003_2022-09-08_10-37-16\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00001_1_batch_size=128,dropout_rate=0.3120,epochs=4,layer_1=16,lr=0.0003_2022-09-08_10-37-16/error.txt\",\n  \"pickled_error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00001_1_batch_size=128,dropout_rate=0.3120,epochs=4,layer_1=16,lr=0.0003_2022-09-08_10-37-16/error.pkl\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00003\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 16,\n    \"lr\": 0.0030069116487011207,\n    \"dropout_rate\": 0.19016860065084,\n    \"batch_size\": 128,\n    \"epochs\": 8\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 16,\n    \"lr\": 0.0030069116487011207,\n    \"dropout_rate\": 0.19016860065084,\n    \"batch_size\": 128,\n    \"epochs\": 8\n  },\n  \"experiment_tag\": \"3_batch_size=128,dropout_rate=0.1902,epochs=8,layer_1=16,lr=0.0030\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"trial_id\": \"6fbf4_00003\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1662626236.7639365,\n  \"relative_logdir\": \"train_with_config_6fbf4_00003_3_batch_size=128,dropout_rate=0.1902,epochs=8,layer_1=16,lr=0.0030_2022-09-08_10-37-16\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00003_3_batch_size=128,dropout_rate=0.1902,epochs=8,layer_1=16,lr=0.0030_2022-09-08_10-37-16/error.txt\",\n  \"pickled_error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00003_3_batch_size=128,dropout_rate=0.1902,epochs=8,layer_1=16,lr=0.0030_2022-09-08_10-37-16/error.pkl\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00002\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 16,\n    \"lr\": 0.012864586611797096,\n    \"dropout_rate\": 0.24111463560630703,\n    \"batch_size\": 32,\n    \"epochs\": 9\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 16,\n    \"lr\": 0.012864586611797096,\n    \"dropout_rate\": 0.24111463560630703,\n    \"batch_size\": 32,\n    \"epochs\": 9\n  },\n  \"experiment_tag\": \"2_batch_size=32,dropout_rate=0.2411,epochs=9,layer_1=16,lr=0.0129\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"trial_id\": \"6fbf4_00002\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1662626236.7566714,\n  \"relative_logdir\": \"train_with_config_6fbf4_00002_2_batch_size=32,dropout_rate=0.2411,epochs=9,layer_1=16,lr=0.0129_2022-09-08_10-37-16\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00002_2_batch_size=32,dropout_rate=0.2411,epochs=9,layer_1=16,lr=0.0129_2022-09-08_10-37-16/error.txt\",\n  \"pickled_error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00002_2_batch_size=32,dropout_rate=0.2411,epochs=9,layer_1=16,lr=0.0129_2022-09-08_10-37-16/error.pkl\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00004\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 4,\n    \"lr\": 0.00020278346886633383,\n    \"dropout_rate\": 0.19762109615600276,\n    \"batch_size\": 32,\n    \"epochs\": 9\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 4,\n    \"lr\": 0.00020278346886633383,\n    \"dropout_rate\": 0.19762109615600276,\n    \"batch_size\": 32,\n    \"epochs\": 9\n  },\n  \"experiment_tag\": \"4_batch_size=32,dropout_rate=0.1976,epochs=9,layer_1=4,lr=0.0002\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"trial_id\": \"6fbf4_00004\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1662626236.7716303,\n  \"relative_logdir\": \"train_with_config_6fbf4_00004_4_batch_size=32,dropout_rate=0.1976,epochs=9,layer_1=4,lr=0.0002_2022-09-08_10-37-16\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00004_4_batch_size=32,dropout_rate=0.1976,epochs=9,layer_1=4,lr=0.0002_2022-09-08_10-37-16/error.txt\",\n  \"pickled_error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00004_4_batch_size=32,dropout_rate=0.1976,epochs=9,layer_1=4,lr=0.0002_2022-09-08_10-37-16/error.pkl\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00000\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 16,\n    \"lr\": 0.06534508186594377,\n    \"dropout_rate\": 0.0864308272380618,\n    \"batch_size\": 128,\n    \"epochs\": 1\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 16,\n    \"lr\": 0.06534508186594377,\n    \"dropout_rate\": 0.0864308272380618,\n    \"batch_size\": 128,\n    \"epochs\": 1\n  },\n  \"experiment_tag\": \"0_batch_size=128,dropout_rate=0.0864,epochs=1,layer_1=16,lr=0.0653\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1662626233.3758852,\n  \"relative_logdir\": \"train_with_config_6fbf4_00000_0_batch_size=128,dropout_rate=0.0864,epochs=1,layer_1=16,lr=0.0653_2022-09-08_10-37-13\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00000_0_batch_size=128,dropout_rate=0.0864,epochs=1,layer_1=16,lr=0.0653_2022-09-08_10-37-13/error.txt\",\n  \"pickled_error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00000_0_batch_size=128,dropout_rate=0.0864,epochs=1,layer_1=16,lr=0.0653_2022-09-08_10-37-13/error.pkl\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00005\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 4,\n    \"lr\": 0.022221516181708083,\n    \"dropout_rate\": 0.2727105215222228,\n    \"batch_size\": 64,\n    \"epochs\": 5\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 4,\n    \"lr\": 0.022221516181708083,\n    \"dropout_rate\": 0.2727105215222228,\n    \"batch_size\": 64,\n    \"epochs\": 5\n  },\n  \"experiment_tag\": \"5_batch_size=64,dropout_rate=0.2727,epochs=5,layer_1=4,lr=0.0222\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"trial_id\": \"6fbf4_00005\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1662626236.778142,\n  \"relative_logdir\": \"train_with_config_6fbf4_00005_5_batch_size=64,dropout_rate=0.2727,epochs=5,layer_1=4,lr=0.0222_2022-09-08_10-37-16\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00005_5_batch_size=64,dropout_rate=0.2727,epochs=5,layer_1=4,lr=0.0222_2022-09-08_10-37-16/error.txt\",\n  \"pickled_error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00005_5_batch_size=64,dropout_rate=0.2727,epochs=5,layer_1=4,lr=0.0222_2022-09-08_10-37-16/error.pkl\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00006\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 2,\n    \"lr\": 0.0058895619915802985,\n    \"dropout_rate\": 0.013732236429514622,\n    \"batch_size\": 32,\n    \"epochs\": 7\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 2,\n    \"lr\": 0.0058895619915802985,\n    \"dropout_rate\": 0.013732236429514622,\n    \"batch_size\": 32,\n    \"epochs\": 7\n  },\n  \"experiment_tag\": \"6_batch_size=32,dropout_rate=0.0137,epochs=7,layer_1=2,lr=0.0059\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1662626238.0932536,\n  \"relative_logdir\": \"train_with_config_6fbf4_00006_6_batch_size=32,dropout_rate=0.0137,epochs=7,layer_1=2,lr=0.0059_2022-09-08_10-37-18\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00006_6_batch_size=32,dropout_rate=0.0137,epochs=7,layer_1=2,lr=0.0059_2022-09-08_10-37-18/error.txt\",\n  \"pickled_error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00006_6_batch_size=32,dropout_rate=0.0137,epochs=7,layer_1=2,lr=0.0059_2022-09-08_10-37-18/error.pkl\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00015\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 4,\n    \"lr\": 0.0016095596803020196,\n    \"dropout_rate\": 0.3396398077164796,\n    \"batch_size\": 64,\n    \"epochs\": 4\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 4,\n    \"lr\": 0.0016095596803020196,\n    \"dropout_rate\": 0.3396398077164796,\n    \"batch_size\": 64,\n    \"epochs\": 4\n  },\n  \"experiment_tag\": \"15_batch_size=64,dropout_rate=0.3396,epochs=4,layer_1=4,lr=0.0016\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1662626252.031865,\n  \"relative_logdir\": \"train_with_config_6fbf4_00015_15_batch_size=64,dropout_rate=0.3396,epochs=4,layer_1=4,lr=0.0016_2022-09-08_10-37-32\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00011\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 4,\n    \"lr\": 0.01687758282344856,\n    \"dropout_rate\": 0.31988449839771,\n    \"batch_size\": 128,\n    \"epochs\": 6\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 4,\n    \"lr\": 0.01687758282344856,\n    \"dropout_rate\": 0.31988449839771,\n    \"batch_size\": 128,\n    \"epochs\": 6\n  },\n  \"experiment_tag\": \"11_batch_size=128,dropout_rate=0.3199,epochs=6,layer_1=4,lr=0.0169\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1662626243.8314338,\n  \"relative_logdir\": \"train_with_config_6fbf4_00011_11_batch_size=128,dropout_rate=0.3199,epochs=6,layer_1=4,lr=0.0169_2022-09-08_10-37-23\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00011_11_batch_size=128,dropout_rate=0.3199,epochs=6,layer_1=4,lr=0.0169_2022-09-08_10-37-23/error.txt\",\n  \"pickled_error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00011_11_batch_size=128,dropout_rate=0.3199,epochs=6,layer_1=4,lr=0.0169_2022-09-08_10-37-23/error.pkl\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00009\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 8,\n    \"lr\": 0.002891050562504788,\n    \"dropout_rate\": 0.1832499241072442,\n    \"batch_size\": 128,\n    \"epochs\": 5\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 8,\n    \"lr\": 0.002891050562504788,\n    \"dropout_rate\": 0.1832499241072442,\n    \"batch_size\": 128,\n    \"epochs\": 5\n  },\n  \"experiment_tag\": \"9_batch_size=128,dropout_rate=0.1832,epochs=5,layer_1=8,lr=0.0029\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1662626243.7817888,\n  \"relative_logdir\": \"train_with_config_6fbf4_00009_9_batch_size=128,dropout_rate=0.1832,epochs=5,layer_1=8,lr=0.0029_2022-09-08_10-37-23\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00009_9_batch_size=128,dropout_rate=0.1832,epochs=5,layer_1=8,lr=0.0029_2022-09-08_10-37-23/error.txt\",\n  \"pickled_error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00009_9_batch_size=128,dropout_rate=0.1832,epochs=5,layer_1=8,lr=0.0029_2022-09-08_10-37-23/error.pkl\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00012\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 8,\n    \"lr\": 0.0002449040411197755,\n    \"dropout_rate\": 0.21668978859134486,\n    \"batch_size\": 128,\n    \"epochs\": 9\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 8,\n    \"lr\": 0.0002449040411197755,\n    \"dropout_rate\": 0.21668978859134486,\n    \"batch_size\": 128,\n    \"epochs\": 9\n  },\n  \"experiment_tag\": \"12_batch_size=128,dropout_rate=0.2167,epochs=9,layer_1=8,lr=0.0002\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1662626244.809313,\n  \"relative_logdir\": \"train_with_config_6fbf4_00012_12_batch_size=128,dropout_rate=0.2167,epochs=9,layer_1=8,lr=0.0002_2022-09-08_10-37-24\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00010\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 2,\n    \"lr\": 0.0006091594192513361,\n    \"dropout_rate\": 0.27107565228366465,\n    \"batch_size\": 128,\n    \"epochs\": 6\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 2,\n    \"lr\": 0.0006091594192513361,\n    \"dropout_rate\": 0.27107565228366465,\n    \"batch_size\": 128,\n    \"epochs\": 6\n  },\n  \"experiment_tag\": \"10_batch_size=128,dropout_rate=0.2711,epochs=6,layer_1=2,lr=0.0006\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1662626243.8071086,\n  \"relative_logdir\": \"train_with_config_6fbf4_00010_10_batch_size=128,dropout_rate=0.2711,epochs=6,layer_1=2,lr=0.0006_2022-09-08_10-37-23\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00007\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 8,\n    \"lr\": 0.010190499653748332,\n    \"dropout_rate\": 0.0919931200775849,\n    \"batch_size\": 64,\n    \"epochs\": 7\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 8,\n    \"lr\": 0.010190499653748332,\n    \"dropout_rate\": 0.0919931200775849,\n    \"batch_size\": 64,\n    \"epochs\": 7\n  },\n  \"experiment_tag\": \"7_batch_size=64,dropout_rate=0.0920,epochs=7,layer_1=8,lr=0.0102\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1662626243.7545016,\n  \"relative_logdir\": \"train_with_config_6fbf4_00007_7_batch_size=64,dropout_rate=0.0920,epochs=7,layer_1=8,lr=0.0102_2022-09-08_10-37-23\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00007_7_batch_size=64,dropout_rate=0.0920,epochs=7,layer_1=8,lr=0.0102_2022-09-08_10-37-23/error.txt\",\n  \"pickled_error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00007_7_batch_size=64,dropout_rate=0.0920,epochs=7,layer_1=8,lr=0.0102_2022-09-08_10-37-23/error.pkl\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00013\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 16,\n    \"lr\": 0.0005133446658114932,\n    \"dropout_rate\": 0.05025732603462312,\n    \"batch_size\": 64,\n    \"epochs\": 5\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 16,\n    \"lr\": 0.0005133446658114932,\n    \"dropout_rate\": 0.05025732603462312,\n    \"batch_size\": 64,\n    \"epochs\": 5\n  },\n  \"experiment_tag\": \"13_batch_size=64,dropout_rate=0.0503,epochs=5,layer_1=16,lr=0.0005\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1662626251.9781048,\n  \"relative_logdir\": \"train_with_config_6fbf4_00013_13_batch_size=64,dropout_rate=0.0503,epochs=5,layer_1=16,lr=0.0005_2022-09-08_10-37-31\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00016\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 2,\n    \"lr\": 0.002169486740433697,\n    \"dropout_rate\": 0.16722225927977036,\n    \"batch_size\": 64,\n    \"epochs\": 6\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 2,\n    \"lr\": 0.002169486740433697,\n    \"dropout_rate\": 0.16722225927977036,\n    \"batch_size\": 64,\n    \"epochs\": 6\n  },\n  \"experiment_tag\": \"16_batch_size=64,dropout_rate=0.1672,epochs=6,layer_1=2,lr=0.0022\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1662626252.039714,\n  \"relative_logdir\": \"train_with_config_6fbf4_00016_16_batch_size=64,dropout_rate=0.1672,epochs=6,layer_1=2,lr=0.0022_2022-09-08_10-37-32\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00008\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 4,\n    \"lr\": 0.00415782479456345,\n    \"dropout_rate\": 0.1176911289083046,\n    \"batch_size\": 64,\n    \"epochs\": 1\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 4,\n    \"lr\": 0.00415782479456345,\n    \"dropout_rate\": 0.1176911289083046,\n    \"batch_size\": 64,\n    \"epochs\": 1\n  },\n  \"experiment_tag\": \"8_batch_size=64,dropout_rate=0.1177,epochs=1,layer_1=4,lr=0.0042\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1662626243.7618291,\n  \"relative_logdir\": \"train_with_config_6fbf4_00008_8_batch_size=64,dropout_rate=0.1177,epochs=1,layer_1=4,lr=0.0042_2022-09-08_10-37-23\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00008_8_batch_size=64,dropout_rate=0.1177,epochs=1,layer_1=4,lr=0.0042_2022-09-08_10-37-23/error.txt\",\n  \"pickled_error_file\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/train_with_config_6fbf4_00008_8_batch_size=64,dropout_rate=0.1177,epochs=1,layer_1=4,lr=0.0042_2022-09-08_10-37-23/error.pkl\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_with_config\",\n  \"trial_id\": \"6fbf4_00014\",\n  \"config\": {\n    \"input_dim\": 37,\n    \"layer_1\": 8,\n    \"lr\": 0.03320159031613113,\n    \"dropout_rate\": 0.042604324900864035,\n    \"batch_size\": 32,\n    \"epochs\": 4\n  },\n  \"local_dir\": \"/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation\",\n  \"evaluated_params\": {\n    \"layer_1\": 8,\n    \"lr\": 0.03320159031613113,\n    \"dropout_rate\": 0.042604324900864035,\n    \"batch_size\": 32,\n    \"epochs\": 4\n  },\n  \"experiment_tag\": \"14_batch_size=32,dropout_rate=0.0426,epochs=4,layer_1=8,lr=0.0332\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1662626251.9903753,\n  \"relative_logdir\": \"train_with_config_6fbf4_00014_14_batch_size=32,dropout_rate=0.0426,epochs=4,layer_1=8,lr=0.0332_2022-09-08_10-37-31\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"custom_syncer\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e75628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f6461746194681b8c11436865636b706f696e7453746f726167659493944b01859452948c026964944e8c0c73746f726167655f6d6f6465944e8c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 16,
    "_metric": null,
    "_total_time": 0,
    "_iteration": 31,
    "_has_errored": true,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1662626233.226297,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-09-08_10-37-13",
    "checkpoint_file": "/home/rozierale/Work/Rte/Challenge_prev_marges/challenge_margin_2022/ray/consommation/experiment_state-2022-09-08_10-37-13.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1662626233.226297,
    "timestamp": 1662626257.0617766
  }
}